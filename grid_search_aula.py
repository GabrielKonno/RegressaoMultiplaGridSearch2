# -*- coding: utf-8 -*-
"""Grid_Search_Aula.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bcyX8-0UnaUeLRi1PPz3DRwCGQ75-Kd4
"""

import pandas as pd
import numpy as np

from sklearn.datasets import make_moons
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn import metrics

features = pd.read_excel("temps.xlsx")
features.head()

features.describe()

# One-hot encode the data using pandas get_dummies
features = pd.get_dummies(features)
features.head()

labels = np.array(features['actual'])

features= features.drop('actual', axis = 1)

feature_list = list(features.columns)

features = np.array(features)

train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)

"""## Treino com GradientBoostingRegressor"""

grb = GradientBoostingRegressor(n_estimators=100)
grb.fit(train_features, train_labels)
gbr_pred = grb.predict(test_features)

errors_gbr = abs(gbr_pred - test_labels)


r_sq = grb.score(test_features, test_labels)
print('Coeficiente de Determinação (R²):', r_sq)

print('MAE:', metrics.mean_absolute_error(test_labels, gbr_pred))
print('MSE:', metrics.mean_squared_error(test_labels, gbr_pred))
print('RMSE:', np.sqrt(metrics.mean_squared_error(test_labels, gbr_pred)))

"""## GridSearch GradientBoosting"""

from sklearn.model_selection import GridSearchCV


parameters = {'learning_rate': [0.03],
                  'subsample'    : [0.2],
                  'n_estimators' : [100,500,1000, 1500],
                  'max_depth'    : [8]
                 }

grid_search = GridSearchCV(grb, parameters, scoring='r2', cv=2, n_jobs=-1)

grid_search.fit(train_features, train_labels)

print(" Results from Grid Search " )
    print("\n The best estimator across ALL searched params:\n",grid_search.best_estimator_)
    print("\n The best score across ALL searched params:\n",grid_search.best_score_)
    print("\n The best parameters across ALL searched params:\n",grid_search.best_params_)

best_model = grid_search.best_estimator_

best_model.get_params()

grb_tunned = GradientBoostingRegressor(alpha = 0.9,  ccp_alpha = 0.0,
 criterion = 'friedman_mse',
 init = None,
 learning_rate = 0.03,
 loss = 'squared_error',
 max_depth = 8,
 max_features = None,
 max_leaf_nodes = None,
 min_impurity_decrease = 0.0,
 min_samples_leaf = 1,
 min_samples_split = 2,
 min_weight_fraction_leaf = 0.0,
 n_estimators = 100,
 n_iter_no_change = None,
 random_state = None,
 subsample = 0.2,
 tol = 0.0001,
 validation_fraction = 0.1,
 verbose = 0,
 warm_start = False)
grb_tunned.fit(train_features, train_labels)
gbr_tunned_pred = grb_tunned.predict(test_features)

errors_gbr = abs(gbr_tunned_pred - test_labels)


r_sq = grb_tunned.score(test_features, test_labels)
print('Coeficiente de Determinação (R²):', r_sq)

print('MAE:', metrics.mean_absolute_error(test_labels, gbr_tunned_pred))
print('MSE:', metrics.mean_squared_error(test_labels, gbr_tunned_pred))
print('RMSE:', np.sqrt(metrics.mean_squared_error(test_labels, gbr_tunned_pred)))

